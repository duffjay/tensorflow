{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2\n",
    "#### MNIST - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecatioin warnings\n",
    "mnist_data = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784  # flattened images 28x28 as a vector\n",
    "no_classes = 10\n",
    "batch_size = 100\n",
    "total_batches = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "y_input = tf.placeholder(tf.float32, shape=[None, no_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "#### Summary Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variable_summary(tf_variable, summary_name):\n",
    "    with tf.name_scope(summary_name + '_summary'):\n",
    "        # calc mean\n",
    "        mean = tf.reduce_mean(tf_variable)\n",
    "        tf.summary.scalar('Mean', mean)\n",
    "        # calc std dev\n",
    "        with tf.name_scope('standard_deviation'):\n",
    "            standard_deviation = tf.sqrt(tf.reduce_mean(tf.square(tf_variable - mean)))\n",
    "            \n",
    "        tf.summary.scalar('StandardDeviation', standard_deviation)\n",
    "        tf.summary.scalar('Maximum', tf.reduce_max(tf_variable))\n",
    "        tf.summary.scalar('Minimum', tf.reduce_min(tf_variable))\n",
    "        tf.summary.histogram('Histogram', tf_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data\n",
    "shape each MNIST digit as 28x28x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape operation\n",
    "x_input_reshape = tf.reshape(x_input, [-1,28,28,1], name='input_reshape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer Function\n",
    "return a convolution layer  \n",
    "include a tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_layer(input_layer, filters, kernel_size=[3,3], activation=tf.nn.relu):\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        activation=activation)\n",
    "    add_variable_summary(layer, 'convolution')\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer Function\n",
    "return a pooling layer  \n",
    "include a tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer(input_layer, pool_size=[2,2], strides=2):\n",
    "    layer = tf.layers.max_pooling2d(\n",
    "        inputs=input_layer,\n",
    "        pool_size=pool_size,\n",
    "        strides=strides)\n",
    "    add_variable_summary(layer, 'pooling')\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer Function\n",
    "input - a single dimension (flat) vector  \n",
    " a hidden layer (units), 1024 in this example  \n",
    "output reLU activation   \n",
    "return a dense layer  \n",
    "\n",
    "include a tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(input_layer,units, activation=tf.nn.relu):\n",
    "    layer = tf.layers.dense(\n",
    "        inputs=input_layer,\n",
    "        units=units,\n",
    "        activation=activation)\n",
    "    add_variable_summary(layer, 'dense')\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 1\n",
    "convolution_layer_1 = convolution_layer(x_input_reshape, 64)   # 64 filters\n",
    "pooling_layer_1 = pooling_layer(convolution_layer_1)\n",
    "\n",
    "# layer 2\n",
    "convolution_layer_2 = convolution_layer(pooling_layer_1, 128)  # 128 filters\n",
    "pooling_layer_2 = pooling_layer(convolution_layer_2)\n",
    "\n",
    "flattened_pool = tf.reshape(pooling_layer_2, [-1, 5*5*128], name = 'flattened_pool')    # n, 5x5, filters\n",
    "\n",
    "dense_layer_bottleneck = dense_layer(flattened_pool, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop Out\n",
    "layer 2 -> boolean x Dropout -> Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_bool = tf.placeholder(tf.bool)  # placeholder\n",
    "dropout_layer = tf.layers.dropout(\n",
    "    inputs=dense_layer_bottleneck,\n",
    "    rate=0.4,\n",
    "    training=dropout_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = dense_layer(dropout_layer, no_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=y_input, logits=logits)\n",
    "    loss_operation = tf.reduce_mean(softmax_cross_entropy, name='loss')\n",
    "    tf.summary.scalar('loss', loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Optimizer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        predictions = tf.argmax(logits, 1)\n",
    "        correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy_operation = tf.reduce_mean(\n",
    "            tf.cast(correct_predictions, tf.float32))\n",
    "        \n",
    "tf.summary.scalar('accuracy', accuracy_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session & Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Writer\n",
    "the graph is written once  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary_operation = tf.summary.merge_all()\n",
    "train_summary_writer = tf.summary.FileWriter('/tmp/train', session.graph)\n",
    "test_summary_writer  = tf.summary.FileWriter('/tmp/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for batch_no in range(total_batches):\n",
    "    # retreive a batch\n",
    "    mnist_batch = mnist_data.train.next_batch(batch_size)\n",
    "    train_images, train_labels = mnist_batch[0], mnist_batch[1]\n",
    "    if batch_no == 0:\n",
    "        print (\"train_Images\", train_images.shape)\n",
    "        print (\"train_labels\", train_labels.shape)\n",
    "    print (\"batch#\", batch_no)\n",
    "    # run the batch through the model\n",
    "    #   merged_summary is the outut values of the optimizer\n",
    "    _, merged_summary = session.run([optimizer, merged_summary_operation], feed_dict={\n",
    "        x_input: train_images,\n",
    "        y_input: train_labels,\n",
    "        dropout_bool: True\n",
    "    })\n",
    "    # summary_writer\n",
    "    train_summary_writer.add_summary(merged_summary, batch_no)\n",
    "    # add test statistics every 10th loop\n",
    "    if batch_no % 10 == 0:\n",
    "        merged_summary, _ = session.run([merged_summary_operation, accuracy_operation], feed_dict={\n",
    "            x_input: test_images,\n",
    "            y_input: test_labels,\n",
    "            dropout_bool: False\n",
    "        })\n",
    "        test_summary_writer.add_summary(merged_summary, batch_no)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
